version: '3.8'

services:
  api:
    build: ./backend
    env_file: .env
    ports: ['${API_PORT:-8000}:8000']
    depends_on:
      db: { condition: service_healthy }
      redis: { condition: service_healthy }
      neo4j: { condition: service_healthy }
      ollama: { condition: service_started }
    healthcheck:
      test: ['CMD', 'curl', '-fsS', 'http://localhost:8000/healthz']
      interval: 10s
      timeout: 3s
      retries: 12
    command: ['/app/entrypoint.sh']
    restart: unless-stopped

  worker:
    build: ./backend
    env_file: .env
    depends_on:
      api: { condition: service_healthy }
      redis: { condition: service_healthy }
    command: ['celery', '-A', 'app.celery_app', 'worker', '--loglevel=INFO']
    restart: unless-stopped

  frontend:
    build: ./frontend
    env_file: .env
    ports: ['${FRONTEND_PORT:-3000}:3000']
    depends_on:
      api: { condition: service_started }
    restart: unless-stopped

  db:
    image: postgres:15
    environment: { POSTGRES_USER: app, POSTGRES_PASSWORD: app, POSTGRES_DB: app }
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U app -d app']
      interval: 5s
      timeout: 5s
      retries: 40

  redis:
    image: redis:7
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 3s
      retries: 40

  neo4j:
    image: neo4j:5
    environment: { NEO4J_AUTH: '${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-neo4jpassword}' }
    healthcheck:
      test: ['CMD-SHELL', 'wget -qO- http://localhost:7474 || exit 1']
      interval: 10s
      timeout: 5s
      retries: 60
    ports: ['7474:7474', '7687:7687']

  ollama:
    image: ollama/ollama:latest
    volumes:
      - ./docker/prometheus:/etc/prometheus
    networks:
      - codeinsight-network
  # v1 Stable - Production ready (CodeBERT)
  v1_stable:
    build: ./ai_versions/v1_stable
    ports:
      - '8000:8000'
    environment:
      - MODEL_PATH=/model
      - AI_VERSION=v1
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8000/health']
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - ai-network
      - ./ai_models:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    ports: ['11434:11434']
    restart: unless-stopped

  # v2 Experimental - New tech testing (Llama2)
  v2_experimental:
    build: ./ai_versions/v2_experimental
    ports:
      - '8001:8000' # Separate port for testing
    environment:
      - MODEL_PATH=/model
      - AI_VERSION=v2
      - GPU_ENABLED=true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8000/health']
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - ai-network

  # v3 Deprecated - Failed tech archive (GPT-3.5)
  v3_deprecated:
    image: alpine:3.18
    volumes:
      - ./ai_versions/v3_deprecated:/archive:ro
    environment:
      - AI_VERSION=v3
      - ARCHIVE_MODE=true
    networks:
      - ai-network
    # No runtime - just for storage

  # Version Router - Dynamic routing
  version_router:
    build:
      context: .
      dockerfile: Dockerfile.router
    ports:
      - '8090:8000'
    environment:
      - DEFAULT_VERSION=v1
      - V1_PATH=/app/ai_versions/v1_stable
      - V2_PATH=/app/ai_versions/v2_experimental
      - V3_PATH=/app/ai_versions/v3_deprecated
    volumes:
      - ./ai_versions:/app/ai_versions:ro
    depends_on:
      - v1_stable
      - v2_experimental
    networks:
      - ai-network
    healthcheck:
      test: ['CMD', 'curl', '-fsS', 'http://localhost:8000/healthz']
      interval: 10s
      timeout: 3s
      retries: 12
    command: ['/app/entrypoint.sh']
    restart: unless-stopped

  worker:
    build: ./backend
    env_file: .env
    depends_on:
      api: { condition: service_healthy }
      redis: { condition: service_healthy }
    command: ['celery', '-A', 'app.celery_app', 'worker', '--loglevel=INFO']
    restart: unless-stopped

  frontend:
    build: ./frontend
    env_file: .env
    ports: ['${FRONTEND_PORT:-3000}:3000']
    depends_on:
      api: { condition: service_started }
    restart: unless-stopped

  db:
    image: postgres:15
    environment: { POSTGRES_USER: app, POSTGRES_PASSWORD: app, POSTGRES_DB: app }
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U app -d app']
      interval: 5s
      timeout: 5s
      retries: 40

  redis:
    image: redis:7
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 3s
      retries: 40

  neo4j:
    image: neo4j:5
    environment: { NEO4J_AUTH: '${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-neo4jpassword}' }
    healthcheck:
      test: ['CMD-SHELL', 'wget -qO- http://localhost:7474 || exit 1']
      interval: 10s
      timeout: 5s
      retries: 60
    ports: ['7474:7474', '7687:7687']

  ollama:
    image: ollama/ollama:latest
    volumes:
      - ./ai_models:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    ports: ['11434:11434']
    restart: unless-stopped

volumes:
  postgres_data:
  neo4j_data:
  redis_data:

networks:
  ai-network:
    driver: bridge

volumes:
  ai_versions:
    driver: local
