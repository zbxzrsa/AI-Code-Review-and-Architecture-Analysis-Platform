name: CI Enhanced
on:
  push:
    branches: [main, stable, next, legacy]
  pull_request:
    branches: [main]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Cache dependencies for faster builds
  setup-cache:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Cache node
        uses: actions/cache@v3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

  # Backend quality checks
  backend-quality:
    runs-on: ubuntu-latest
    needs: setup-cache
    strategy:
      matrix:
        python-version: ['3.11']
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt
            backend/requirements-dev.txt

      - name: Install backend dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Lint and format
        working-directory: backend
        run: |
          ruff check . --output-format=github
          black --check --diff .
          isort --check-only --diff .

      - name: Type check
        working-directory: backend
        run: mypy . --junit-xml=mypy-report.xml || true

      - name: Security scan
        working-directory: backend
        run: |
          bandit -r app/ -f json -o bandit-report.json || true
          safety check --json --output=safety-report.json || true

      - name: Unit tests with coverage
        working-directory: backend
        run: |
          pytest tests/unit/ -v --maxfail=1 --cov=app --cov-report=xml --cov-report=html --junit-xml=test-report.xml

      - name: Upload coverage
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage-${{ matrix.python-version }}
          path: |
            backend/htmlcov/
            backend/coverage.xml
            backend/test-report.xml
            backend/mypy-report.xml
            backend/bandit-report.json
            backend/safety-report.json

  # Frontend quality checks
  frontend-quality:
    runs-on: ubuntu-latest
    needs: setup-cache
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Lint
        working-directory: frontend
        run: npm run lint --if-present

      - name: Type check
        working-directory: frontend
        run: npm run type-check --if-present

      - name: Unit tests
        working-directory: frontend
        env:
          CI: true
        run: npm test -- --watchAll=false --coverage

      - name: Upload coverage
        uses: actions/upload-artifact@v4
        with:
          name: frontend-coverage
          path: frontend/coverage/

  # AI Evaluation smoke test
  ai-eval-smoke:
    runs-on: ubuntu-latest
    needs: setup-cache
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt

      - name: Install dependencies
        working-directory: backend
        run: |
          pip install -r requirements.txt
          pip install sentence-transformers scikit-learn || true  # Optional for eval

      - name: Run AI eval smoke test
        working-directory: backend
        run: |
          python -m backend.ai.eval \
            --channel stable \
            --dataset datasets/ai_eval/base.jsonl \
            --offline \
            --output ./eval-smoke-results

      - name: Upload eval results
        uses: actions/upload-artifact@v4
        with:
          name: ai-eval-smoke
          path: backend/eval-smoke-results/

  # Structured JSON Smoke Test
  structured-json-smoke:
    runs-on: ubuntu-latest
    needs: setup-cache
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt

      - name: Install dependencies
        working-directory: backend
        run: |
          pip install -r requirements.txt
          pip install pydantic pytest pytest-mock || true

      - name: Set environment for structured mode
        working-directory: backend
        run: |
          echo "AI_STRUCTURED_MODE=true" >> $GITHUB_ENV
          echo "STABLE_MODEL=mistral:7b-instruct" >> $GITHUB_ENV
          echo "NEXT_MODEL=qwen2:1.5b-instruct" >> $GITHUB_ENV
          echo "LEGACY_MODEL=qwen2:0.5b-instruct" >> $GITHUB_ENV

      - name: Run structured JSON smoke tests
        working-directory: backend
        run: |
          # Test prompt loading
          python -c "
          from ai.engines.shared.prompt_loader import load_prompt, validate_prompt_structure
          for channel in ['stable', 'next', 'legacy']:
              body, front_matter = load_prompt(channel)
              assert validate_prompt_structure(channel), f'Invalid prompt structure for {channel}'
              print(f'✓ {channel} prompt loaded and validated')
          "

      - name: Test JSON schema validation
        working-directory: backend
        run: |
          python -c "
          import json
          from ai.engines.shared.schema import parse_and_validate

          # Test each channel schema
          test_cases = {
              'stable': {
                  'summary': 'Test review',
                  'risk_level': 'low',
                  'key_findings': [],
                  'recommendations': [],
                  'meta': {'channel': 'stable', 'style': 'conservative', 'constraints': ['offline']}
              },
              'next': {
                  'summary': 'Experimental test',
                  'risk_level': 'medium', 
                  'experiments_considered': [],
                  'key_findings': [],
                  'recommendations': [],
                  'guardrails': [],
                  'meta': {'channel': 'next', 'style': 'experimental', 'constraints': ['offline']}
              },
              'legacy': {
                  'summary': 'Quick test',
                  'risk_level': 'low',
                  'key_findings': [],
                  'recommendations': [],
                  'meta': {'channel': 'legacy', 'style': 'baseline-fast', 'constraints': ['offline']}
              }
          }

          for channel, test_data in test_cases.items():
              result = parse_and_validate(channel, json.dumps(test_data))
              assert result['meta']['channel'] == channel
              print(f'✓ {channel} schema validation passed')
          "

      - name: Test RAG citations
        working-directory: backend
        run: |
          python -c "
          from ai.rag.citations import format_context, extract_citations_from_text, merge_citations

          # Test context formatting
          snippets = [
              {'file': 'test.py', 'start': 1, 'end': 3, 'text': 'def test(): pass'}
          ]
          context_text, citations = format_context(snippets)
          assert 'test.py:1-3' in context_text
          assert len(citations) == 1
          print('✓ RAG context formatting works')

          # Test citation extraction
          text = 'Issue in app.py:45 and utils.py:123-125'
          extracted = extract_citations_from_text(text)
          assert len(extracted) == 2
          print('✓ Citation extraction works')
          "

      - name: Test JSON utilities
        working-directory: backend
        run: |
          python -c "
          from ai.engines.shared.json_utils import safe_json_loads, ensure_json_only

          # Test JSON repair
          broken_json = '{\"key\": \"value\",}'
          fixed = safe_json_loads(broken_json)
          assert fixed['key'] == 'value'
          print('✓ JSON repair works')

          # Test JSON extraction
          mixed_text = 'Prefix {\"extracted\": true} Suffix'
          extracted = ensure_json_only(mixed_text)
          parsed = safe_json_loads(extracted)
          assert parsed['extracted'] == True
          print('✓ JSON extraction works')
          "

      - name: Mock engine integration test
        working-directory: backend
        run: |
          python -c "
          import json
          from unittest.mock import Mock, patch

          # Mock stable engine
          with patch('ai.engines.stable.requests.post') as mock_post:
              mock_response = Mock()
              mock_response.json.return_value = {
                  'message': {
                      'content': json.dumps({
                          'summary': 'Mock review',
                          'risk_level': 'low',
                          'key_findings': [],
                          'recommendations': [],
                          'meta': {'channel': 'stable', 'style': 'conservative', 'constraints': ['offline']}
                      })
                  }
              }
              mock_response.raise_for_status.return_value = None
              mock_post.return_value = mock_response
              
              from ai.engines.stable import review
              result = review(text='def test(): pass', context=[], meta={'use_rag': False})
              assert result['summary'] == 'Mock review'
              assert result['meta']['channel'] == 'stable'
              print('✓ Stable engine integration works')
          "

      - name: Run pytest structured tests
        working-directory: backend
        run: |
          pytest tests/ai/test_structured_review.py -v --tb=short || true

      - name: Upload structured test results
        uses: actions/upload-artifact@v4
        with:
          name: structured-json-smoke-results
          path: |
            backend/pytest-structured-results.xml
            backend/structured-smoke.log

  # Contract testing with schemathesis
  contract-test:
    runs-on: ubuntu-latest
    needs: setup-cache
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt

      - name: Install dependencies
        working-directory: backend
        run: |
          pip install -r requirements.txt
          pip install schemathesis || true

      - name: Start backend for contract testing
        working-directory: backend
        run: |
          nohup uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          sleep 5

      - name: Run contract tests
        run: |
          schemathesis run http://localhost:8000/openapi.json \
            --base-url=http://localhost:8000 \
            --hypothesis-max-examples=100 \
            --report=contract-test-report.json || true

      - name: Upload contract test results
        uses: actions/upload-artifact@v4
        with:
          name: contract-test-results
          path: contract-test-report.json

  # Playwright E2E smoke test
  e2e-smoke:
    runs-on: ubuntu-latest
    needs: [backend-quality, frontend-quality]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps

      - name: Start services
        run: |
          docker compose -f docker-compose.yml up -d
          sleep 30

      - name: Run E2E smoke test
        working-directory: frontend
        run: |
          npx playwright test tests/e2e/smoke.spec.ts --reporter=json || true

      - name: Upload E2E results
        uses: actions/upload-artifact@v4
        with:
          name: e2e-smoke-results
          path: frontend/playwright-report/

  # Integration tests
  integration-tests:
    runs-on: ubuntu-latest
    needs: backend-quality
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: app
          POSTGRES_USER: app
          POSTGRES_PASSWORD: app
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U app -d app"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt

      - name: Install dependencies
        working-directory: backend
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run integration tests
        working-directory: backend
        run: |
          pytest tests/integration/ -v --maxfail=1 --junit-xml=integration-test-report.xml || true

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: backend/integration-test-report.xml
